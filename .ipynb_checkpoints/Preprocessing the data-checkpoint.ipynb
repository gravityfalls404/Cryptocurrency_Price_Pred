{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7453674e213a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"crypto_data/{csv_files[0]}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_files' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(f\"crypto_data/{csv_files[0]}\", names = ['Time', 'Low', 'High', 'Open', 'Close', 'Volume'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETH-USD\n",
      "BCH-USD\n",
      "LTC-USD\n",
      "BTC-USD\n",
      "            ETH-USD_Close  ETH-USD_Volume  BCH-USD_Close  BCH-USD_Volume  \\\n",
      "Time                                                                       \n",
      "1528968720      486.01001       26.019083     870.859985       26.856577   \n",
      "1528968780      486.00000        8.449400     870.099976        1.124300   \n",
      "1528968840      485.75000       26.994646     870.789978        1.749862   \n",
      "1528968900      486.00000       77.355759     870.000000        1.680500   \n",
      "1528968960      486.00000        7.503300     869.989990        1.669014   \n",
      "\n",
      "            LTC-USD_Close  LTC-USD_Volume  BTC-USD_Close  BTC-USD_Volume  \n",
      "Time                                                                      \n",
      "1528968720      96.660004      314.387024    6487.379883        7.706374  \n",
      "1528968780      96.570000       77.129799    6479.410156        3.088252  \n",
      "1528968840      96.500000        7.216067    6479.410156        1.404100  \n",
      "1528968900      96.389999      524.539978    6479.979980        0.753000  \n",
      "1528968960      96.519997       16.991997    6480.000000        1.490900  \n"
     ]
    }
   ],
   "source": [
    "# Rading all the data files \n",
    "csv_files = []\n",
    "path = \"./crypto_data/\"\n",
    "for file in os.listdir(path):\n",
    "    csv_files.append(file.split(\".\")[0])\n",
    "\n",
    "main_df = pd.DataFrame()\n",
    "# # Combining all the Crypto data in a single dataframe\n",
    "for crypto in csv_files:\n",
    "    print(crypto)\n",
    "    data = f\"./crypto_data/{crypto}.csv\"\n",
    "    df = pd.read_csv(data, names=['Time', 'Low', 'High', 'Open', 'Close', 'Volume'])\n",
    "    \n",
    "    df.rename(columns={\"Close\": f\"{crypto}_Close\", \"Volume\": f\"{crypto}_Volume\"}, inplace=True)\n",
    "    df.set_index(\"Time\", inplace=True)\n",
    "    df = df[[f\"{crypto}_Close\",f\"{crypto}_Volume\"]]\n",
    "    \n",
    "    if len(main_df)==0:\n",
    "        main_df = df\n",
    "    else:\n",
    "        main_df = main_df.join(df)\n",
    "main_df.fillna(method=\"ffill\", inplace = True)\n",
    "main_df.dropna(inplace = True)\n",
    "print(main_df.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the parameters for the NN\n",
    "SEQ_LEN = 60\n",
    "FUTUTE_PERIOD_PREDICT = 3\n",
    "RATIO_TO_PREDICT = \"ETH-USD\"\n",
    "\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ETH-USD_Close  ETH-USD_Volume  BCH-USD_Close  BCH-USD_Volume  \\\n",
      "Time                                                                       \n",
      "1528968720      486.01001       26.019083     870.859985       26.856577   \n",
      "1528968780      486.00000        8.449400     870.099976        1.124300   \n",
      "1528968840      485.75000       26.994646     870.789978        1.749862   \n",
      "1528968900      486.00000       77.355759     870.000000        1.680500   \n",
      "1528968960      486.00000        7.503300     869.989990        1.669014   \n",
      "\n",
      "            LTC-USD_Close  LTC-USD_Volume  BTC-USD_Close  BTC-USD_Volume  \\\n",
      "Time                                                                       \n",
      "1528968720      96.660004      314.387024    6487.379883        7.706374   \n",
      "1528968780      96.570000       77.129799    6479.410156        3.088252   \n",
      "1528968840      96.500000        7.216067    6479.410156        1.404100   \n",
      "1528968900      96.389999      524.539978    6479.979980        0.753000   \n",
      "1528968960      96.519997       16.991997    6480.000000        1.490900   \n",
      "\n",
      "               Future  Target  \n",
      "Time                           \n",
      "1528968720  486.00000       0  \n",
      "1528968780  486.00000       0  \n",
      "1528968840  485.98999       1  \n",
      "1528968900  485.98999       0  \n",
      "1528968960  485.98999       0  \n"
     ]
    }
   ],
   "source": [
    "main_df['Future'] = main_df[f\"{RATIO_TO_PREDICT}_Close\"].shift(-FUTUTE_PERIOD_PREDICT)\n",
    "main_df['Target'] = list(map(classify, main_df[f\"{RATIO_TO_PREDICT}_Close\"], main_df['Future']))\n",
    "print(main_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In order to make a validation set out of the current dataset we have to take a percentage \n",
    "## from that dataset as a validation data\n",
    "\n",
    "VAL_PCT = 0.10   #10% of all the data is validation data\n",
    "times = sorted(main_df.index.values)\n",
    "\n",
    "#Getting the index values of the last VAL_PCT i.e time stamp value \n",
    "final_pct = sorted(main_df.index.values)[-int(VAL_PCT*len(times))] \n",
    "\n",
    "validation_main_df = main_df[(main_df.index >= final_pct)] #Taking all records which have a time stamp more than the VAL_PCT timestamp\n",
    "main_df = main_df[(main_df.index < final_pct)] # Rest are under training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing #To notmalize and scale the data\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = df.drop(\"Future\",1) #This is the actual future value to be used later for regression model\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col != \"Target\":\n",
    "            df[col] = df[col].pct_change() #Since the abs values of differet bitcoins are vastly differe so we measure only the pct change  to feed the model.\n",
    "            df.dropna(inplace = True)\n",
    "            df[col] = preprocessing.scale(df[col].values) #0-1\n",
    "    \n",
    "    df.dropna(inplace=True) #In case we missed any NAN value\n",
    "    \n",
    "    sequential_data = [] #Cointains a seq of timestaps along with the values and a target corrosponding to SEQ_LEN\n",
    "    prev_days = deque(maxlen=SEQ_LEN) #Queue that'll only store maxlen values\n",
    "\n",
    "    for record in df.values: \n",
    "        prev_days.append([col for col in record[:-1]]) #appending all the colums except the target to the queue \n",
    "\n",
    "        if len(prev_days) == SEQ_LEN: #If the temp sequence len reaches the seq_len value\n",
    "            sequential_data.append([np.array(prev_days), record[-1]]) #Append the sequence to the sequential data list\n",
    "\n",
    "    random.shuffle(sequential_data) \n",
    "    \n",
    "    \"\"\"\n",
    "        Before feeding the data to the newtwork there should be a balance between the\n",
    "        number of different categories of data i.e around 50-50\n",
    "    \"\"\"\n",
    "    \n",
    "    buys = [] #When the target value is 0 (Price goes down)\n",
    "    sells = [] # whent the target values is 1 (Price goes up)\n",
    "    \n",
    "    \n",
    "    for seq, target in sequential_data: \n",
    "        if target ==0:\n",
    "            sells.append([seq, target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq, target])\n",
    "    \n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    #Getting the min len out of the 1 and 0 and mixing them in equal number i.e. 50-50\n",
    "    lower = min(len(buys), len(sells))\n",
    "    \n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "    \n",
    "    sequential_data = buys+sells\n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "        \n",
    "    \n",
    "    return np.array(X),y #Returns the array of sequence along with the target values\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 92481 validation: 10216\n",
      "Dont buys: 50884, buys: 41597\n",
      "VALIDATION Dont buys: 5618, buys: 4598\n"
     ]
    }
   ],
   "source": [
    "#Getting the training and validation input and target from the data\n",
    "\n",
    "train_x, train_y  = preprocess_df(main_df)\n",
    "validation_x, validation_y = preprocess_df(validation_main_df)\n",
    "\n",
    "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
    "print(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
    "print(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
